{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e82qHAvNORcJ",
        "colab_type": "code",
        "outputId": "f53bff4e-b73b-4028-edd5-31c54c90834a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Change google colab working directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "my_project_dir = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "os.chdir(my_project_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pezg0nOdhp7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modify source list\n",
        "with open('/etc/apt/sources.list') as f: \n",
        "  txt = f.read() \n",
        "  with open('/etc/apt/sources.list', 'w') as f: \n",
        "    f.write(txt.replace('# deb-src','deb-src'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z52Sqif9hsNm",
        "colab_type": "code",
        "outputId": "49673b18-3f32-48b2-9458-c5bfbd579d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%shell\n",
        "# Install caffe deps\n",
        "sudo apt update\n",
        "sudo apt build-dep caffe-cuda\n",
        "sudo apt build-dep caffe\n",
        "sudo apt install python3-opencv\n",
        "sudo apt-get install libatlas-base-dev\n",
        "sudo apt-get install libopenblas-dev\n",
        "sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\n",
        "sudo apt-get install --install-recommends libboost-all-dev\n",
        "sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "sudo pip install protobuf\n",
        "sudo pip3 install protobuf\n",
        "\n",
        "# Set default gcc to gcc v5 since newer version not compatible\n",
        "##sudo apt-get install gcc-5 g++-5\n",
        "##sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 1 --slave /usr/bin/g++ g++ /usr/bin/g++-7 # Change accordingly with default gcc version\n",
        "##sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 2 --slave /usr/bin/g++ g++ /usr/bin/g++-5\n",
        "##sudo update-alternatives --auto gcc\n",
        "#sudo update-alternatives --config gcc # Uncomment this line to manually select gcc version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://archive.canonical.com/ubuntu bionic InRelease [10.2 kB]\n",
            "\r            \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 10.2 kB/10.2 kB 100%] [2 InR\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com] [2 InRelease 14.2 kB/88.7 kB 16%] [Connec\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 10.2 kB] [Connecting to archive.ubuntu.com] [2 InRelease 1\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 10.2 kB] [Connecting to archive.ubuntu.com (91.189.88.173)\u001b[0m\r                                                                               \rGet:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "\u001b[33m\r0% [1 InRelease gpgv 10.2 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Waiting for heade\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Conn\u001b[0m\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Conn\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\r                                                                               \rGet:6 http://archive.canonical.com/ubuntu bionic/partner Sources [1,901 B]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\u001b[33m\r0% [6 Sources store 0 B] [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Conn\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\r                                                                               \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\r                                                                               \rGet:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Waiting for heade\u001b[0m\r                                                                               \rGet:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/multiverse Sources [3,233 B]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/restricted Sources [4,532 B]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe Sources [208 kB]\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main Sources [169 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [6,783 B]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [18.9 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [759 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [794 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/restricted Sources [5,823 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/multiverse Sources [216 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [34.2 kB]\n",
            "Get:26 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [25.5 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main Sources [1,063 kB]\n",
            "Get:28 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,741 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe Sources [11.5 MB]\n",
            "Get:30 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main Sources [385 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/restricted Sources [6,867 B]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/universe Sources [356 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse Sources [6,205 B]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,056 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,321 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [10.5 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [32.7 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic-backports/universe Sources [2,533 B]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic-backports/main Sources [2,569 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4,244 B]\n",
            "Get:42 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [840 kB]\n",
            "Fetched 20.9 MB in 3s (6,437 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "41 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Picking 'caffe-contrib' as source package instead of 'caffe-cuda'\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev bash-completion bc cpp-6 cython3\n",
            "  debhelper dh-autoreconf dh-strip-nondeterminism file fonts-lyx g++-6 gcc-6\n",
            "  gcc-6-base gettext gettext-base intltool-debian ipython3 libaccinj64-9.1\n",
            "  libarchive-zip-perl libasan3 libcublas9.1 libcudart9.1 libcufft9.1\n",
            "  libcufftw9.1 libcuinj64-9.1 libcurand9.1 libcusolver9.1 libcusparse9.1\n",
            "  libfile-stripnondeterminism-perl libgcc-6-dev libgflags-dev libgflags2.2\n",
            "  libgoogle-glog-dev libgoogle-glog0v5 libjs-jquery-ui libleveldb-dev\n",
            "  libleveldb1v5 liblmdb-dev liblmdb0 libmagic-mgc libmagic1 libnppc9.1\n",
            "  libnppial9.1 libnppicc9.1 libnppicom9.1 libnppidei9.1 libnppif9.1\n",
            "  libnppig9.1 libnppim9.1 libnppist9.1 libnppisu9.1 libnppitc9.1 libnpps9.1\n",
            "  libnvblas9.1 libnvgraph9.1 libnvrtc9.1 libnvtoolsext1 libnvvm3\n",
            "  libprotobuf-dev libprotobuf-lite10 libprotoc-dev libsigsegv2 libsnappy-dev\n",
            "  libstdc++-6-dev libthrust-dev libtimedate-perl libtool m4 nvidia-cuda-dev\n",
            "  nvidia-cuda-toolkit nvidia-profiler po-debconf python-matplotlib-data\n",
            "  python3-cycler python3-dateutil python3-decorator python3-gflags\n",
            "  python3-h5py python3-ipython python3-ipython-genutils python3-leveldb\n",
            "  python3-matplotlib python3-networkx python3-nose python3-pandas\n",
            "  python3-pandas-lib python3-pexpect python3-pickleshare python3-pil\n",
            "  python3-pkg-resources python3-prompt-toolkit python3-protobuf\n",
            "  python3-ptyprocess python3-pydotplus python3-pygments python3-pyparsing\n",
            "  python3-pywt python3-scipy python3-simplegeneric python3-six python3-skimage\n",
            "  python3-skimage-lib python3-traitlets python3-tz python3-wcwidth\n",
            "  python3-yaml ttf-bitstream-vera\n",
            "0 upgraded, 110 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 643 MB of archives.\n",
            "After this operation, 1,735 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.3 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.3 [68.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.3 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-yaml amd64 3.12-1build2 [109 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 bash-completion all 1:2.8-1ubuntu1 [168 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext-base amd64 0.19.8.1-6ubuntu0.3 [113 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 autopoint all 0.19.8.1-6ubuntu0.3 [426 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 bc amd64 1.07.1-2 [86.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gcc-6-base amd64 6.5.0-2ubuntu1~18.04 [16.7 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 cpp-6 amd64 6.5.0-2ubuntu1~18.04 [6,396 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cython3 amd64 0.26.1-0.4 [1,925 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libasan3 amd64 6.5.0-2ubuntu1~18.04 [313 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libgcc-6-dev amd64 6.5.0-2ubuntu1~18.04 [2,308 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gcc-6 amd64 6.5.0-2ubuntu1~18.04 [7,067 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-autoreconf all 17 [15.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libarchive-zip-perl all 1.60-1ubuntu0.1 [84.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-stripnondeterminism-perl all 0.040-1.1~build1 [13.8 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-strip-nondeterminism all 0.040-1.1~build1 [5,208 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext amd64 0.19.8.1-6ubuntu0.3 [1,293 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 intltool-debian all 0.35.0+20060710.4 [24.9 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 po-debconf all 1.0.20 [232 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 debhelper all 11.1.6ubuntu2 [902 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 fonts-lyx all 2.2.4-0ubuntu0.18.04.1 [155 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libstdc++-6-dev amd64 6.5.0-2ubuntu1~18.04 [1,437 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 g++-6 amd64 6.5.0-2ubuntu1~18.04 [7,213 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-decorator all 4.1.2-1 [9,364 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-ptyprocess all 0.5.2-1 [12.7 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pexpect all 4.2.1-1 [42.4 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pickleshare all 0.7.4-2 [6,904 B]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wcwidth all 0.1.7+dfsg1-1 [14.7 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-prompt-toolkit all 1.0.15-1 [163 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pygments all 2.2.0+dfsg-1 [574 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-simplegeneric all 0.8.1-1 [11.5 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-ipython-genutils all 0.2.0-1 [20.9 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-traitlets all 4.3.2-1 [59.1 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-ipython all 5.5.0-1 [381 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ipython3 all 5.5.0-1 [5,304 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libaccinj64-9.1 amd64 9.1.85-3ubuntu1 [1,748 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcublas9.1 amd64 9.1.85-3ubuntu1 [25.0 MB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcudart9.1 amd64 9.1.85-3ubuntu1 [121 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcufft9.1 amd64 9.1.85-3ubuntu1 [76.1 MB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcufftw9.1 amd64 9.1.85-3ubuntu1 [131 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcuinj64-9.1 amd64 9.1.85-3ubuntu1 [1,878 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcurand9.1 amd64 9.1.85-3ubuntu1 [38.9 MB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcusolver9.1 amd64 9.1.85-3ubuntu1 [28.2 MB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcusparse9.1 amd64 9.1.85-3ubuntu1 [25.2 MB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags2.2 amd64 2.2.1-1 [72.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags-dev amd64 2.2.1-1 [86.1 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog0v5 amd64 0.3.5-1 [50.5 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog-dev amd64 0.3.5-1 [73.8 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjs-jquery-ui all 1.12.1+dfsg-5 [232 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb1v5 amd64 1.20-2 [136 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb-dev amd64 1.20-2 [177 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 liblmdb0 amd64 0.9.21-1ubuntu0.1 [44.6 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 liblmdb-dev amd64 0.9.21-1ubuntu0.1 [59.6 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppc9.1 amd64 9.1.85-3ubuntu1 [127 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppial9.1 amd64 9.1.85-3ubuntu1 [3,169 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppicc9.1 amd64 9.1.85-3ubuntu1 [1,376 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppicom9.1 amd64 9.1.85-3ubuntu1 [497 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppidei9.1 amd64 9.1.85-3ubuntu1 [1,673 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppif9.1 amd64 9.1.85-3ubuntu1 [20.9 MB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppig9.1 amd64 9.1.85-3ubuntu1 [9,960 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppim9.1 amd64 9.1.85-3ubuntu1 [2,295 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppist9.1 amd64 9.1.85-3ubuntu1 [4,910 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppisu9.1 amd64 9.1.85-3ubuntu1 [120 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppitc9.1 amd64 9.1.85-3ubuntu1 [714 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnpps9.1 amd64 9.1.85-3ubuntu1 [2,568 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvblas9.1 amd64 9.1.85-3ubuntu1 [132 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvgraph9.1 amd64 9.1.85-3ubuntu1 [6,252 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvrtc9.1 amd64 9.1.85-3ubuntu1 [6,309 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ttf-bitstream-vera all 1.10-8 [352 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-matplotlib-data all 2.1.1-2ubuntu3 [3,774 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-cycler all 0.10.0-1 [7,622 B]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-dateutil all 2.6.1-1 [52.3 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-gflags all 1.5.1-5 [35.6 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-h5py amd64 2.7.1-2 [631 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-leveldb amd64 0~svn68-3build3 [18.3 kB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pyparsing all 2.2.0+dfsg1-2 [52.2 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-tz all 2018.3-2 [25.1 kB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-matplotlib amd64 2.1.1-2ubuntu3 [3,907 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-networkx all 1.11-1ubuntu3 [606 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-nose all 1.3.7-3 [115 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pandas-lib amd64 0.22.0-4 [3,041 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pandas all 0.22.0-4 [2,764 kB]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pil amd64 5.1.0-1 [328 kB]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-protobuf amd64 3.0.0-9.1ubuntu1 [262 kB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pydotplus all 2.0.2-2 [20.2 kB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pywt amd64 0.5.1-1.1ubuntu4 [932 kB]\n",
            "Get:99 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-scipy amd64 0.19.1-2ubuntu1 [9,619 kB]\n",
            "Get:100 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-skimage-lib amd64 0.13.1-2 [1,504 kB]\n",
            "Get:101 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-skimage all 0.13.1-2 [19.6 MB]\n",
            "Get:102 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvtoolsext1 amd64 9.1.85-3ubuntu1 [31.3 kB]\n",
            "Get:103 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvvm3 amd64 9.1.85-3ubuntu1 [4,274 kB]\n",
            "Get:104 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
            "Get:105 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotoc-dev amd64 3.0.0-9.1ubuntu1 [682 kB]\n",
            "Get:106 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsnappy-dev amd64 1.1.7-1 [27.2 kB]\n",
            "Get:107 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libthrust-dev all 1.9.1~9.1.85-3ubuntu1 [461 kB]\n",
            "Get:108 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-cuda-dev amd64 9.1.85-3ubuntu1 [263 MB]\n",
            "Get:109 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-profiler amd64 9.1.85-3ubuntu1 [2,672 kB]\n",
            "Get:110 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-cuda-toolkit amd64 9.1.85-3ubuntu1 [30.4 MB]\n",
            "Fetched 643 MB in 27s (24.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 110.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 135718 files and directories currently installed.)\n",
            "Preparing to unpack .../000-libmagic-mgc_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../001-libmagic1_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../002-file_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package python3-yaml.\n",
            "Preparing to unpack .../003-python3-yaml_3.12-1build2_amd64.deb ...\n",
            "Unpacking python3-yaml (3.12-1build2) ...\n",
            "Selecting previously unselected package bash-completion.\n",
            "Preparing to unpack .../004-bash-completion_1%3a2.8-1ubuntu1_all.deb ...\n",
            "Unpacking bash-completion (1:2.8-1ubuntu1) ...\n",
            "Selecting previously unselected package gettext-base.\n",
            "Preparing to unpack .../005-gettext-base_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "Preparing to unpack .../006-libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../007-m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../008-autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../009-autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../010-automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Selecting previously unselected package autopoint.\n",
            "Preparing to unpack .../011-autopoint_0.19.8.1-6ubuntu0.3_all.deb ...\n",
            "Unpacking autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package bc.\n",
            "Preparing to unpack .../012-bc_1.07.1-2_amd64.deb ...\n",
            "Unpacking bc (1.07.1-2) ...\n",
            "Selecting previously unselected package gcc-6-base:amd64.\n",
            "Preparing to unpack .../013-gcc-6-base_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package cpp-6.\n",
            "Preparing to unpack .../014-cpp-6_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking cpp-6 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package cython3.\n",
            "Preparing to unpack .../015-cython3_0.26.1-0.4_amd64.deb ...\n",
            "Unpacking cython3 (0.26.1-0.4) ...\n",
            "Selecting previously unselected package libasan3:amd64.\n",
            "Preparing to unpack .../016-libasan3_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking libasan3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package libgcc-6-dev:amd64.\n",
            "Preparing to unpack .../017-libgcc-6-dev_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking libgcc-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package gcc-6.\n",
            "Preparing to unpack .../018-gcc-6_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking gcc-6 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package libtool.\n",
            "Preparing to unpack .../019-libtool_2.4.6-2_all.deb ...\n",
            "Unpacking libtool (2.4.6-2) ...\n",
            "Selecting previously unselected package dh-autoreconf.\n",
            "Preparing to unpack .../020-dh-autoreconf_17_all.deb ...\n",
            "Unpacking dh-autoreconf (17) ...\n",
            "Selecting previously unselected package libarchive-zip-perl.\n",
            "Preparing to unpack .../021-libarchive-zip-perl_1.60-1ubuntu0.1_all.deb ...\n",
            "Unpacking libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libfile-stripnondeterminism-perl.\n",
            "Preparing to unpack .../022-libfile-stripnondeterminism-perl_0.040-1.1~build1_all.deb ...\n",
            "Unpacking libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../023-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package dh-strip-nondeterminism.\n",
            "Preparing to unpack .../024-dh-strip-nondeterminism_0.040-1.1~build1_all.deb ...\n",
            "Unpacking dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package gettext.\n",
            "Preparing to unpack .../025-gettext_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package intltool-debian.\n",
            "Preparing to unpack .../026-intltool-debian_0.35.0+20060710.4_all.deb ...\n",
            "Unpacking intltool-debian (0.35.0+20060710.4) ...\n",
            "Selecting previously unselected package po-debconf.\n",
            "Preparing to unpack .../027-po-debconf_1.0.20_all.deb ...\n",
            "Unpacking po-debconf (1.0.20) ...\n",
            "Selecting previously unselected package debhelper.\n",
            "Preparing to unpack .../028-debhelper_11.1.6ubuntu2_all.deb ...\n",
            "Unpacking debhelper (11.1.6ubuntu2) ...\n",
            "Selecting previously unselected package fonts-lyx.\n",
            "Preparing to unpack .../029-fonts-lyx_2.2.4-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking fonts-lyx (2.2.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libstdc++-6-dev:amd64.\n",
            "Preparing to unpack .../030-libstdc++-6-dev_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking libstdc++-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package g++-6.\n",
            "Preparing to unpack .../031-g++-6_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking g++-6 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package python3-decorator.\n",
            "Preparing to unpack .../032-python3-decorator_4.1.2-1_all.deb ...\n",
            "Unpacking python3-decorator (4.1.2-1) ...\n",
            "Selecting previously unselected package python3-ptyprocess.\n",
            "Preparing to unpack .../033-python3-ptyprocess_0.5.2-1_all.deb ...\n",
            "Unpacking python3-ptyprocess (0.5.2-1) ...\n",
            "Selecting previously unselected package python3-pexpect.\n",
            "Preparing to unpack .../034-python3-pexpect_4.2.1-1_all.deb ...\n",
            "Unpacking python3-pexpect (4.2.1-1) ...\n",
            "Selecting previously unselected package python3-pickleshare.\n",
            "Preparing to unpack .../035-python3-pickleshare_0.7.4-2_all.deb ...\n",
            "Unpacking python3-pickleshare (0.7.4-2) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../036-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../037-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-wcwidth.\n",
            "Preparing to unpack .../038-python3-wcwidth_0.1.7+dfsg1-1_all.deb ...\n",
            "Unpacking python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Selecting previously unselected package python3-prompt-toolkit.\n",
            "Preparing to unpack .../039-python3-prompt-toolkit_1.0.15-1_all.deb ...\n",
            "Unpacking python3-prompt-toolkit (1.0.15-1) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../040-python3-pygments_2.2.0+dfsg-1_all.deb ...\n",
            "Unpacking python3-pygments (2.2.0+dfsg-1) ...\n",
            "Selecting previously unselected package python3-simplegeneric.\n",
            "Preparing to unpack .../041-python3-simplegeneric_0.8.1-1_all.deb ...\n",
            "Unpacking python3-simplegeneric (0.8.1-1) ...\n",
            "Selecting previously unselected package python3-ipython-genutils.\n",
            "Preparing to unpack .../042-python3-ipython-genutils_0.2.0-1_all.deb ...\n",
            "Unpacking python3-ipython-genutils (0.2.0-1) ...\n",
            "Selecting previously unselected package python3-traitlets.\n",
            "Preparing to unpack .../043-python3-traitlets_4.3.2-1_all.deb ...\n",
            "Unpacking python3-traitlets (4.3.2-1) ...\n",
            "Selecting previously unselected package python3-ipython.\n",
            "Preparing to unpack .../044-python3-ipython_5.5.0-1_all.deb ...\n",
            "Unpacking python3-ipython (5.5.0-1) ...\n",
            "Selecting previously unselected package ipython3.\n",
            "Preparing to unpack .../045-ipython3_5.5.0-1_all.deb ...\n",
            "Unpacking ipython3 (5.5.0-1) ...\n",
            "Selecting previously unselected package libaccinj64-9.1:amd64.\n",
            "Preparing to unpack .../046-libaccinj64-9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libaccinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcublas9.1:amd64.\n",
            "Preparing to unpack .../047-libcublas9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcudart9.1:amd64.\n",
            "Preparing to unpack .../048-libcudart9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcufft9.1:amd64.\n",
            "Preparing to unpack .../049-libcufft9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcufft9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcufftw9.1:amd64.\n",
            "Preparing to unpack .../050-libcufftw9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcufftw9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcuinj64-9.1:amd64.\n",
            "Preparing to unpack .../051-libcuinj64-9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcuinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcurand9.1:amd64.\n",
            "Preparing to unpack .../052-libcurand9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcusolver9.1:amd64.\n",
            "Preparing to unpack .../053-libcusolver9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcusolver9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcusparse9.1:amd64.\n",
            "Preparing to unpack .../054-libcusparse9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcusparse9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libgflags2.2.\n",
            "Preparing to unpack .../055-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "Preparing to unpack .../056-libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../057-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../058-libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Selecting previously unselected package libjs-jquery-ui.\n",
            "Preparing to unpack .../059-libjs-jquery-ui_1.12.1+dfsg-5_all.deb ...\n",
            "Unpacking libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../060-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../061-libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../062-liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../063-liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libnppc9.1:amd64.\n",
            "Preparing to unpack .../064-libnppc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppial9.1:amd64.\n",
            "Preparing to unpack .../065-libnppial9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppial9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppicc9.1:amd64.\n",
            "Preparing to unpack .../066-libnppicc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppicc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppicom9.1:amd64.\n",
            "Preparing to unpack .../067-libnppicom9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppicom9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppidei9.1:amd64.\n",
            "Preparing to unpack .../068-libnppidei9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppidei9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppif9.1:amd64.\n",
            "Preparing to unpack .../069-libnppif9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppif9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppig9.1:amd64.\n",
            "Preparing to unpack .../070-libnppig9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppig9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppim9.1:amd64.\n",
            "Preparing to unpack .../071-libnppim9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppim9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppist9.1:amd64.\n",
            "Preparing to unpack .../072-libnppist9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppist9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppisu9.1:amd64.\n",
            "Preparing to unpack .../073-libnppisu9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppisu9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnppitc9.1:amd64.\n",
            "Preparing to unpack .../074-libnppitc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnppitc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnpps9.1:amd64.\n",
            "Preparing to unpack .../075-libnpps9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnpps9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnvblas9.1:amd64.\n",
            "Preparing to unpack .../076-libnvblas9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnvblas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnvgraph9.1:amd64.\n",
            "Preparing to unpack .../077-libnvgraph9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnvgraph9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnvrtc9.1:amd64.\n",
            "Preparing to unpack .../078-libnvrtc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnvrtc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../079-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package ttf-bitstream-vera.\n",
            "Preparing to unpack .../080-ttf-bitstream-vera_1.10-8_all.deb ...\n",
            "Unpacking ttf-bitstream-vera (1.10-8) ...\n",
            "Selecting previously unselected package python-matplotlib-data.\n",
            "Preparing to unpack .../081-python-matplotlib-data_2.1.1-2ubuntu3_all.deb ...\n",
            "Unpacking python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-cycler.\n",
            "Preparing to unpack .../082-python3-cycler_0.10.0-1_all.deb ...\n",
            "Unpacking python3-cycler (0.10.0-1) ...\n",
            "Selecting previously unselected package python3-dateutil.\n",
            "Preparing to unpack .../083-python3-dateutil_2.6.1-1_all.deb ...\n",
            "Unpacking python3-dateutil (2.6.1-1) ...\n",
            "Selecting previously unselected package python3-gflags.\n",
            "Preparing to unpack .../084-python3-gflags_1.5.1-5_all.deb ...\n",
            "Unpacking python3-gflags (1.5.1-5) ...\n",
            "Selecting previously unselected package python3-h5py.\n",
            "Preparing to unpack .../085-python3-h5py_2.7.1-2_amd64.deb ...\n",
            "Unpacking python3-h5py (2.7.1-2) ...\n",
            "Selecting previously unselected package python3-leveldb.\n",
            "Preparing to unpack .../086-python3-leveldb_0~svn68-3build3_amd64.deb ...\n",
            "Unpacking python3-leveldb (0~svn68-3build3) ...\n",
            "Selecting previously unselected package python3-pyparsing.\n",
            "Preparing to unpack .../087-python3-pyparsing_2.2.0+dfsg1-2_all.deb ...\n",
            "Unpacking python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Selecting previously unselected package python3-tz.\n",
            "Preparing to unpack .../088-python3-tz_2018.3-2_all.deb ...\n",
            "Unpacking python3-tz (2018.3-2) ...\n",
            "Selecting previously unselected package python3-matplotlib.\n",
            "Preparing to unpack .../089-python3-matplotlib_2.1.1-2ubuntu3_amd64.deb ...\n",
            "Unpacking python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-networkx.\n",
            "Preparing to unpack .../090-python3-networkx_1.11-1ubuntu3_all.deb ...\n",
            "Unpacking python3-networkx (1.11-1ubuntu3) ...\n",
            "Selecting previously unselected package python3-nose.\n",
            "Preparing to unpack .../091-python3-nose_1.3.7-3_all.deb ...\n",
            "Unpacking python3-nose (1.3.7-3) ...\n",
            "Selecting previously unselected package python3-pandas-lib.\n",
            "Preparing to unpack .../092-python3-pandas-lib_0.22.0-4_amd64.deb ...\n",
            "Unpacking python3-pandas-lib (0.22.0-4) ...\n",
            "Selecting previously unselected package python3-pandas.\n",
            "Preparing to unpack .../093-python3-pandas_0.22.0-4_all.deb ...\n",
            "Unpacking python3-pandas (0.22.0-4) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../094-python3-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (5.1.0-1) ...\n",
            "Selecting previously unselected package python3-protobuf.\n",
            "Preparing to unpack .../095-python3-protobuf_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package python3-pydotplus.\n",
            "Preparing to unpack .../096-python3-pydotplus_2.0.2-2_all.deb ...\n",
            "Unpacking python3-pydotplus (2.0.2-2) ...\n",
            "Selecting previously unselected package python3-pywt.\n",
            "Preparing to unpack .../097-python3-pywt_0.5.1-1.1ubuntu4_amd64.deb ...\n",
            "Unpacking python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Selecting previously unselected package python3-scipy.\n",
            "Preparing to unpack .../098-python3-scipy_0.19.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-skimage-lib:amd64.\n",
            "Preparing to unpack .../099-python3-skimage-lib_0.13.1-2_amd64.deb ...\n",
            "Unpacking python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Selecting previously unselected package python3-skimage.\n",
            "Preparing to unpack .../100-python3-skimage_0.13.1-2_all.deb ...\n",
            "Unpacking python3-skimage (0.13.1-2) ...\n",
            "Selecting previously unselected package libnvtoolsext1:amd64.\n",
            "Preparing to unpack .../101-libnvtoolsext1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnvtoolsext1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libnvvm3:amd64.\n",
            "Preparing to unpack .../102-libnvvm3_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libnvvm3:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../103-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libprotoc-dev:amd64.\n",
            "Preparing to unpack .../104-libprotoc-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotoc-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "Preparing to unpack .../105-libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Selecting previously unselected package libthrust-dev.\n",
            "Preparing to unpack .../106-libthrust-dev_1.9.1~9.1.85-3ubuntu1_all.deb ...\n",
            "Unpacking libthrust-dev (1.9.1~9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-cuda-dev.\n",
            "Preparing to unpack .../107-nvidia-cuda-dev_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-dev (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-profiler.\n",
            "Preparing to unpack .../108-nvidia-profiler_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-profiler (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-cuda-toolkit.\n",
            "Preparing to unpack .../109-nvidia-cuda-toolkit_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-toolkit (9.1.85-3ubuntu1) ...\n",
            "Setting up libcufft9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-yaml (3.12-1build2) ...\n",
            "Setting up libnvtoolsext1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libcusparse9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-pickleshare (0.7.4-2) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up python3-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python3-simplegeneric (0.8.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Setting up libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Setting up libthrust-dev (1.9.1~9.1.85-3ubuntu1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up bash-completion (1:2.8-1ubuntu1) ...\n",
            "Setting up gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up libcuinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Setting up python3-cycler (0.10.0-1) ...\n",
            "Setting up gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-gflags (1.5.1-5) ...\n",
            "update-alternatives: using /usr/bin/python3-gflags2man to provide /usr/bin/gflags2man (gflags2man) in auto mode\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Setting up python3-pandas-lib (0.22.0-4) ...\n",
            "Setting up libnppc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libaccinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Setting up python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Setting up libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libnvrtc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libnppitc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libnppif9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up python3-ipython-genutils (0.2.0-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up python3-nose (1.3.7-3) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up libnvvm3:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Setting up libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up ttf-bitstream-vera (1.10-8) ...\n",
            "Setting up cython3 (0.26.1-0.4) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up cpp-6 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Setting up libcufftw9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up bc (1.07.1-2) ...\n",
            "Setting up libnppim9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libcusolver9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libnvblas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-decorator (4.1.2-1) ...\n",
            "Setting up python3-traitlets (4.3.2-1) ...\n",
            "Setting up python3-ptyprocess (0.5.2-1) ...\n",
            "Setting up python3-tz (2018.3-2) ...\n",
            "Setting up python3-leveldb (0~svn68-3build3) ...\n",
            "Setting up autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up python3-dateutil (2.6.1-1) ...\n",
            "Setting up libnppidei9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-h5py (2.7.1-2) ...\n",
            "Setting up fonts-lyx (2.2.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libnppial9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Setting up python3-pygments (2.2.0+dfsg-1) ...\n",
            "Setting up nvidia-profiler (9.1.85-3ubuntu1) ...\n",
            "Setting up libasan3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Setting up libgcc-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up python3-prompt-toolkit (1.0.15-1) ...\n",
            "Setting up libstdc++-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Setting up libnppicom9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up python3-pydotplus (2.0.2-2) ...\n",
            "Setting up libnppisu9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libnpps9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Setting up libnppicc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libnppist9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up libnppig9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up libnvgraph9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up file (1:5.32-2ubuntu0.3) ...\n",
            "Setting up nvidia-cuda-dev (9.1.85-3ubuntu1) ...\n",
            "Setting up gcc-6 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up g++-6 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up intltool-debian (0.35.0+20060710.4) ...\n",
            "Setting up python3-pexpect (4.2.1-1) ...\n",
            "Setting up python3-networkx (1.11-1ubuntu3) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Setting up nvidia-cuda-toolkit (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-pandas (0.22.0-4) ...\n",
            "Setting up libprotoc-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Setting up libtool (2.4.6-2) ...\n",
            "Setting up po-debconf (1.0.20) ...\n",
            "Setting up python3-ipython (5.5.0-1) ...\n",
            "Setting up python3-skimage (0.13.1-2) ...\n",
            "Setting up ipython3 (5.5.0-1) ...\n",
            "Setting up dh-autoreconf (17) ...\n",
            "Setting up debhelper (11.1.6ubuntu2) ...\n",
            "Setting up dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  cm-super-minimal doxygen doxygen-latex fonts-lmodern ghostscript\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libmime-charset-perl libpotrace0 libptexenc1 libsombok3 libsynctex1\n",
            "  libtexlua52 libtexluajit2 libunicode-linebreak-perl libxapian30 libzzip-0-13\n",
            "  poppler-data preview-latex-style t1utils tex-common texlive-base\n",
            "  texlive-binaries texlive-extra-utils texlive-font-utils\n",
            "  texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures\n",
            "0 upgraded, 34 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 110 MB of archives.\n",
            "After this operation, 326 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.7 [18.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.12 [5,092 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.12 [2,264 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super-minimal all 0.3.4-11 [5,810 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 doxygen amd64 1.8.13-10 [3,880 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsombok3 amd64 2.4.0-1 [27.2 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmime-charset-perl all 1.012.2-1 [30.9 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libunicode-linebreak-perl amd64 0.0.20160702-1build2 [96.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-extra-utils all 2017.20180305-2 [20.9 MB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-font-utils all 2017.20180305-2 [1,721 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.12 [50.9 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 doxygen-latex all 1.8.13-10 [5,236 B]\n",
            "Fetched 110 MB in 6s (19.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 34.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-data.\n",
            "(Reading database ... 148037 files and directories currently installed.)\n",
            "Preparing to unpack .../00-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../01-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../02-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../03-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../04-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../05-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../06-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../07-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../08-libcupsimage2_2.2.7-1ubuntu2.7_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.7) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../09-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../10-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../11-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.12_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.12) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../12-libgs9_9.26~dfsg+0-0ubuntu0.18.04.12_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.12) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../13-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../14-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../15-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../16-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../17-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../18-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../19-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "Preparing to unpack .../20-cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../21-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package doxygen.\n",
            "Preparing to unpack .../22-doxygen_1.8.13-10_amd64.deb ...\n",
            "Unpacking doxygen (1.8.13-10) ...\n",
            "Selecting previously unselected package libsombok3:amd64.\n",
            "Preparing to unpack .../23-libsombok3_2.4.0-1_amd64.deb ...\n",
            "Unpacking libsombok3:amd64 (2.4.0-1) ...\n",
            "Selecting previously unselected package libmime-charset-perl.\n",
            "Preparing to unpack .../24-libmime-charset-perl_1.012.2-1_all.deb ...\n",
            "Unpacking libmime-charset-perl (1.012.2-1) ...\n",
            "Selecting previously unselected package libunicode-linebreak-perl.\n",
            "Preparing to unpack .../25-libunicode-linebreak-perl_0.0.20160702-1build2_amd64.deb ...\n",
            "Unpacking libunicode-linebreak-perl (0.0.20160702-1build2) ...\n",
            "Selecting previously unselected package texlive-extra-utils.\n",
            "Preparing to unpack .../26-texlive-extra-utils_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-extra-utils (2017.20180305-2) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../27-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../28-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../29-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-font-utils.\n",
            "Preparing to unpack .../30-texlive-font-utils_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-font-utils (2017.20180305-2) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../31-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.12_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.12) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../32-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package doxygen-latex.\n",
            "Preparing to unpack .../33-doxygen-latex_1.8.13-10_all.deb ...\n",
            "Unpacking doxygen-latex (1.8.13-10) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.12) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up doxygen (1.8.13-10) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.7) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up libmime-charset-perl (1.012.2-1) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.12) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libsombok3:amd64 (2.4.0-1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.12) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up libunicode-linebreak-perl (0.0.20160702-1build2) ...\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-extra-utils (2017.20180305-2) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up texlive-font-utils (2017.20180305-2) ...\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up doxygen-latex (1.8.13-10) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  python3-opencv\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 534 kB of archives.\n",
            "After this operation, 2,941 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [534 kB]\n",
            "Fetched 534 kB in 1s (737 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-opencv.\n",
            "(Reading database ... 166071 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libatlas-base-dev is already the newest version (3.10.3-5).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libleveldb-dev is already the newest version (1.20-2).\n",
            "libprotobuf-dev is already the newest version (3.0.0-9.1ubuntu1).\n",
            "libsnappy-dev is already the newest version (1.1.7-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "libopencv-dev is already the newest version (3.2.0+dfsg-4ubuntu0.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  libhdf5-serial-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 2,898 B of archives.\n",
            "After this operation, 37.9 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhdf5-serial-dev all 1.10.0-patch1+docs-4 [2,898 B]\n",
            "Fetched 2,898 B in 0s (14.6 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "(Reading database ... 166075 files and directories currently installed.)\n",
            "Preparing to unpack .../libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libboost-all-dev is already the newest version (1.65.1.0ubuntu1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgflags-dev is already the newest version (2.2.1-1).\n",
            "libgoogle-glog-dev is already the newest version (0.3.5-1).\n",
            "liblmdb-dev is already the newest version (0.9.21-1ubuntu0.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf) (42.0.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf) (42.0.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf) (1.12.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HO5dQpshx4g",
        "colab_type": "code",
        "outputId": "cd6d59e1-0f6b-497f-fdfc-103b5ef43d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "source": [
        "%%shell\n",
        "# Install cuda 10.0 and cudnn 7.4.1\n",
        "sudo apt-get install cuda-10-0\n",
        "\n",
        "mkdir /tmp/cudnn\n",
        "cd Cudnn\\ 7.4.1\n",
        "cp * /tmp/cudnn \n",
        "cd /tmp/cudnn\n",
        "dpkg -i libcudnn7*.deb\n",
        "\n",
        "# Checking install version of cuda and cudnn\n",
        "cat /usr/local/cuda/version.txt # Should be output cuda 10.0\n",
        "cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2 # Should be cudnn 7.4.1\n",
        "# # You should download compatible cudnn for your system configuration\n",
        "# cd Cudnn\\ 7.4.1\n",
        "# dpkg -i libcudnn7*.deb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-10-0 is already the newest version (10.0.130-1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\n",
            "  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1\n",
            "  cuda-cusparse-dev-10-1 cuda-license-10-2 cuda-npp-10-1 cuda-npp-dev-10-1\n",
            "  cuda-nsight-10-1 cuda-nsight-compute-10-1 cuda-nsight-systems-10-1\n",
            "  cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n",
            "  cuda-nvjpeg-dev-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvvp-10-1\n",
            "  libcublas10 libnvidia-common-430 nsight-compute-2019.5.0\n",
            "  nsight-systems-2019.5.2\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn7 from 7.6.5.32-1+cuda10.1 to 7.4.1.5-1+cuda10.0\n",
            "(Reading database ... 166079 files and directories currently installed.)\n",
            "Preparing to unpack libcudnn7_7.4.1.5-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libcudnn7 (7.4.1.5-1+cuda10.0) over (7.6.5.32-1+cuda10.1) ...\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn7-dev from 7.6.5.32-1+cuda10.1 to 7.4.1.5-1+cuda10.0\n",
            "Preparing to unpack libcudnn7-dev_7.4.1.5-1+cuda10.0_amd64.deb ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "Unpacking libcudnn7-dev (7.4.1.5-1+cuda10.0) over (7.6.5.32-1+cuda10.1) ...\n",
            "Selecting previously unselected package libcudnn7-doc.\n",
            "Preparing to unpack libcudnn7-doc_7.4.1.5-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libcudnn7-doc (7.4.1.5-1+cuda10.0) ...\n",
            "Setting up libcudnn7 (7.4.1.5-1+cuda10.0) ...\n",
            "Setting up libcudnn7-dev (7.4.1.5-1+cuda10.0) ...\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v7.h to provide /usr/include/cudnn.h (libcudnn) in auto mode\n",
            "Setting up libcudnn7-doc (7.4.1.5-1+cuda10.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "CUDA Version 10.0.130\n",
            "#define CUDNN_MAJOR 7\n",
            "#define CUDNN_MINOR 4\n",
            "#define CUDNN_PATCHLEVEL 1\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "#include \"driver_types.h\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZbugAdgh0rI",
        "colab_type": "code",
        "outputId": "6949836e-a5a6-454d-8b63-667a516329cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "%%shell\n",
        "# modify install.sh to your cudnn and cuda install location \n",
        "cd /tmp\n",
        "git clone https://github.com/hoquangnam45/dnndk_3.1_dummy.git\n",
        "cd /tmp/dnndk_3.1_dummy\n",
        "git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dnndk_3.1_dummy'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/28)\u001b[K\rremote: Counting objects:   7% (2/28)\u001b[K\rremote: Counting objects:  10% (3/28)\u001b[K\rremote: Counting objects:  14% (4/28)\u001b[K\rremote: Counting objects:  17% (5/28)\u001b[K\rremote: Counting objects:  21% (6/28)\u001b[K\rremote: Counting objects:  25% (7/28)\u001b[K\rremote: Counting objects:  28% (8/28)\u001b[K\rremote: Counting objects:  32% (9/28)\u001b[K\rremote: Counting objects:  35% (10/28)\u001b[K\rremote: Counting objects:  39% (11/28)\u001b[K\rremote: Counting objects:  42% (12/28)\u001b[K\rremote: Counting objects:  46% (13/28)\u001b[K\rremote: Counting objects:  50% (14/28)\u001b[K\rremote: Counting objects:  53% (15/28)\u001b[K\rremote: Counting objects:  57% (16/28)\u001b[K\rremote: Counting objects:  60% (17/28)\u001b[K\rremote: Counting objects:  64% (18/28)\u001b[K\rremote: Counting objects:  67% (19/28)\u001b[K\rremote: Counting objects:  71% (20/28)\u001b[K\rremote: Counting objects:  75% (21/28)\u001b[K\rremote: Counting objects:  78% (22/28)\u001b[K\rremote: Counting objects:  82% (23/28)\u001b[K\rremote: Counting objects:  85% (24/28)\u001b[K\rremote: Counting objects:  89% (25/28)\u001b[K\rremote: Counting objects:  92% (26/28)\u001b[K\rremote: Counting objects:  96% (27/28)\u001b[K\rremote: Counting objects: 100% (28/28)\u001b[K\rremote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 379 (delta 18), reused 19 (delta 9), pack-reused 351\u001b[K\n",
            "Receiving objects: 100% (379/379), 1.73 GiB | 35.94 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "Checking out files: 100% (751/751), done.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbW4u5GWh3GN",
        "colab_type": "code",
        "outputId": "6fc9346d-d079-43c6-e11e-946a9ce00ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%shell\n",
        "# Install cuda 10.0 and cudnn 7.4.1 \n",
        "cd /tmp/dnndk_3.1_dummy/host_x86\n",
        "chmod +x install.sh\n",
        "\n",
        "# Install all cuda host tool\n",
        "./install.sh\n",
        "cd decent-tf/ubuntu18.04\n",
        "python -m pip install tensorflow_gpu-1.12.0-cp27-cp27mu-linux_x86_64.whl\n",
        "python3 -m pip install tensorflow_gpu-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
        "python -m pip install numpy opencv-python sklearn scipy progressbar2\n",
        "python3 -m pip install numpy opencv-python sklearn scipy progressbar2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/dnndk_3.1_dummy/host_x86\n",
            "decent.sh\t dnnc_ZCU102.sh  dnnc_ZedBoard.sh  float.prototxt\n",
            "dnnc_Ultra96.sh  dnnc_ZCU104.sh  float.caffemodel\n",
            "decent.sh\t dnnc_ZCU102.sh  dnnc_ZedBoard.sh  float.prototxt\n",
            "dnnc_Ultra96.sh  dnnc_ZCU104.sh  float.caffemodel\n",
            "tensorflow-1.12.0-cp27-cp27mu-linux_x86_64.whl\n",
            "tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
            "tensorflow_gpu-1.12.0-cp27-cp27mu-linux_x86_64.whl\n",
            "tensorflow_gpu-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
            "tensorflow-1.12.0-cp27-cp27mu-linux_x86_64.whl\n",
            "tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
            "tensorflow_gpu-1.12.0-cp27-cp27mu-linux_x86_64.whl\n",
            "tensorflow_gpu-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
            "tensorflow-1.12.0-cp27-cp27mu-linux_x86_64.whl\n",
            "tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
            "tensorflow_gpu-1.12.0-cp27-cp27mu-linux_x86_64.whl\n",
            "tensorflow_gpu-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
            "Inspect system environment ...\n",
            "[system version]\n",
            "No LSB modules are available.\n",
            "18.04\n",
            "[CUDA version]\n",
            "10.0\n",
            "[CUDNN version]\n",
            "7.4.1\n",
            "Begin to install Xilinx DNNDK tools on host ...\n",
            "Complete dnnc installation successfully.\n",
            "Complete CPU version of decent for caffe installation successfully.\n",
            "Complete GPU version of decent installation successfully.\n",
            "\u001b[31mERROR: tensorflow_gpu-1.12.0-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Processing ./tensorflow_gpu-1.12.0-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.0.8)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.17.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.12.0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0) (42.0.1)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.12.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-gpu-1.12.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.3.3)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (3.38.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from progressbar2) (1.12.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2) (2.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.3.3)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (3.38.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from progressbar2) (1.12.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2) (2.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AufSk3pnkMzc",
        "colab_type": "code",
        "outputId": "a7fc87c2-aa39-41ea-86b3-fa231ead8ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test dnndk install\n",
        "!cat /etc/dnndk.conf\n",
        "!decent\n",
        "!decent_q\n",
        "!dnnc\n",
        "!dlet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# This is the configuration file for Xilinx DNNDK.\n",
            "# It is automatically generated by host_x86/install.sh of DNNDK package.\n",
            "\n",
            "DNNDK_VERSION=3.1\n",
            "DPU_VERSION=1.4.0\n",
            "BOARD_NAME=ZCU102,ZCU104,ZedBoard,Ultra96\n",
            "\n",
            "decent: command line brew\n",
            "usage: decent <command> <args>\n",
            "\n",
            "commands:\n",
            "  quantize        quantize a float model (need calibration with dataset) and deploy to DPU\n",
            "example:\n",
            "  1. quantize:                           ./decent quantize -model float.prototxt -weights float.caffemodel -gpu 0\n",
            "  2. quantize with auto test:            ./decent quantize -model float.prototxt -weights float.caffemodel -gpu 0 -auto_test -test_iter 50\n",
            "  3. quantize with Non-Overflow method:  ./decent quantize -model float.prototxt -weights float.caffemodel -gpu 0 -method 0\n",
            "\n",
            "\n",
            "  Flags from tools/decent.cpp:\n",
            "    -ap_style (Optional: AP computing styles for detection net, including:\n",
            "      11point, MaxIntegral, Integral) type: string default: \"11point\"\n",
            "    -auto_test (Optional: Whether to test after calibration, need test dataset)\n",
            "      type: bool default: false\n",
            "    -calib_iter (Optional: Total iterations for quantize calibration)\n",
            "      type: int32 default: 100\n",
            "    -data_bit (Optional: Bit width for activation data during quantization)\n",
            "      type: int32 default: 8\n",
            "    -gpu (Optional: The GPU device id for calibration and test) type: string\n",
            "      default: \"0\"\n",
            "    -ignore_layers (Optinal: List of layers to be ignore during quantization,\n",
            "      comma-delimited) type: string default: \"\"\n",
            "    -ignore_layers_file (Optional: Prototxt file which defines the layers to be\n",
            "      ignore during quantization, each line formated as 'ignore_layer:\n",
            "      \"layer_name\"') type: string default: \"\"\n",
            "    -input_blob (Optional: Name of input data blob) type: string\n",
            "      default: \"data\"\n",
            "    -method (Optional: Method for quantization, 0: Non-Overflow, 1: Min-Diff)\n",
            "      type: int32 default: 0\n",
            "    -model (The model definition protocol buffer text file) type: string\n",
            "      default: \"\"\n",
            "    -net_type (Optional: Net types for net testing, including: classification,\n",
            "      detection, segmentation, other) type: string default: \"\"\n",
            "    -output_dir (Optional: Output directory for the quantization results)\n",
            "      type: string default: \"./quantize_results\"\n",
            "    -seg_class_num (Optional; The number of segmentation classes) type: int32\n",
            "      default: 19\n",
            "    -seg_metric (Optional; Test metric for segmentation net, now only classIOU\n",
            "      is supported) type: string default: \"classIOU\"\n",
            "    -sigmoided_layers (Optinal: List of layers before sigmoid operation, to be\n",
            "      quantized with optimization for sigmoid accuracy) type: string\n",
            "      default: \"\"\n",
            "    -solver (The solver for finetuning or training) type: string default: \"\"\n",
            "    -test_iter (Optional: Total iterations for test) type: int32 default: 50\n",
            "    -weights (The pretrained float weights for quantization) type: string\n",
            "      default: \"\"\n",
            "    -weights_bit (Optional: Bit width for weights and bias during quantization)\n",
            "      type: int32 default: 8\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "usage: \n",
            "    usage: decent_q command [Options]\n",
            "    \n",
            "    examples:\n",
            "      show help       : decent_q --help\n",
            "      quantize a model: decent_q quantize --input_frozen_graph frozen_graph.pb --input_nodes xxx --output_nodes yyy --input_shapes zzz --input_fn module.calib_input\n",
            "      inspect a model : decent_q inspect --input_frozen_graph frozen_graph.pb\n",
            "      dump quantized model : decent_q dump --input_frozen_graph frozen_graph.pb --input_fn module.dump_input\n",
            "  \n",
            "decent_q: error: the following arguments are required: command\n",
            "\n",
            "Usage: dnnc [options]\n",
            "\n",
            "Optional options: \n",
            "--help          Print usage and exit.\n",
            "--version       Print dnnc version.\n",
            "--save_kernel   Save kernel information in file(kernel.info).\n",
            "--dump          Dump different information, use commas as delimiter when multiple types are given,\n",
            "                supported list: [ graph, weights, ir, quant_info, log, dcf, all ]. \n",
            "--abi           ABI version binding to N2Cube runtime, supported list: [ 0, 1 ], default abi\n",
            "                version: --abi=1. This option is deprecated since DNNDK v3.0 version and only ABI=1\n",
            "                is supported.\n",
            "--mode          Running mode of DPU: debug(default) or normal.\n",
            "\n",
            "Required options:\n",
            "--parser        Type of parser, supported list: [ caffe, tensorflow ]. If not specified, DNNC will\n",
            "                use caffe parser as default.\n",
            "caffe:\n",
            "--prototxt      Path of prototxt file.\n",
            "--caffemodel    Path of caffemodel file. If not specified, DNNC will compile in Dummy mode.\n",
            "\n",
            "tensorflow:\n",
            "--frozen_pb     Path of frozen pb file.\n",
            "\n",
            "--dcf           Path of dpu configuration file generated by dlet tool.\n",
            "--cpu_arch      Type of cpu arch, supported list: [ arm32, arm64 ].\n",
            "--output_dir    Path of output.\n",
            "--net_name      Name of neural network.\n",
            "\n",
            "Usage: dlet <option>\n",
            " Options are:\n",
            "  -v  --version    Display version of DLet\n",
            "  -f  --file       Specity hardware hand-off(HWH) file\n",
            "  -h  --help       Display the usage of DLet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZm9vgLQmsqf",
        "colab_type": "code",
        "outputId": "25e42faa-530f-4689-c92c-6dadc699cc40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# %%shell\n",
        "# cd /tmp\n",
        "# git clone https://github.com/Xilinx/Edge-AI-Platform-Tutorials.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Edge-AI-Platform-Tutorials'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/75)\u001b[K\rremote: Counting objects:   2% (2/75)\u001b[K\rremote: Counting objects:   4% (3/75)\u001b[K\rremote: Counting objects:   5% (4/75)\u001b[K\rremote: Counting objects:   6% (5/75)\u001b[K\rremote: Counting objects:   8% (6/75)\u001b[K\rremote: Counting objects:   9% (7/75)\u001b[K\rremote: Counting objects:  10% (8/75)\u001b[K\rremote: Counting objects:  12% (9/75)\u001b[K\rremote: Counting objects:  13% (10/75)\u001b[K\rremote: Counting objects:  14% (11/75)\u001b[K\rremote: Counting objects:  16% (12/75)\u001b[K\rremote: Counting objects:  17% (13/75)\u001b[K\rremote: Counting objects:  18% (14/75)\u001b[K\rremote: Counting objects:  20% (15/75)\u001b[K\rremote: Counting objects:  21% (16/75)\u001b[K\rremote: Counting objects:  22% (17/75)\u001b[K\rremote: Counting objects:  24% (18/75)\u001b[K\rremote: Counting objects:  25% (19/75)\u001b[K\rremote: Counting objects:  26% (20/75)\u001b[K\rremote: Counting objects:  28% (21/75)\u001b[K\rremote: Counting objects:  29% (22/75)\u001b[K\rremote: Counting objects:  30% (23/75)\u001b[K\rremote: Counting objects:  32% (24/75)\u001b[K\rremote: Counting objects:  33% (25/75)\u001b[K\rremote: Counting objects:  34% (26/75)\u001b[K\rremote: Counting objects:  36% (27/75)\u001b[K\rremote: Counting objects:  37% (28/75)\u001b[K\rremote: Counting objects:  38% (29/75)\u001b[K\rremote: Counting objects:  40% (30/75)\u001b[K\rremote: Counting objects:  41% (31/75)\u001b[K\rremote: Counting objects:  42% (32/75)\u001b[K\rremote: Counting objects:  44% (33/75)\u001b[K\rremote: Counting objects:  45% (34/75)\u001b[K\rremote: Counting objects:  46% (35/75)\u001b[K\rremote: Counting objects:  48% (36/75)\u001b[K\rremote: Counting objects:  49% (37/75)\u001b[K\rremote: Counting objects:  50% (38/75)\u001b[K\rremote: Counting objects:  52% (39/75)\u001b[K\rremote: Counting objects:  53% (40/75)\u001b[K\rremote: Counting objects:  54% (41/75)\u001b[K\rremote: Counting objects:  56% (42/75)\u001b[K\rremote: Counting objects:  57% (43/75)\u001b[K\rremote: Counting objects:  58% (44/75)\u001b[K\rremote: Counting objects:  60% (45/75)\u001b[K\rremote: Counting objects:  61% (46/75)\u001b[K\rremote: Counting objects:  62% (47/75)\u001b[K\rremote: Counting objects:  64% (48/75)\u001b[K\rremote: Counting objects:  65% (49/75)\u001b[K\rremote: Counting objects:  66% (50/75)\u001b[K\rremote: Counting objects:  68% (51/75)\u001b[K\rremote: Counting objects:  69% (52/75)\u001b[K\rremote: Counting objects:  70% (53/75)\u001b[K\rremote: Counting objects:  72% (54/75)\u001b[K\rremote: Counting objects:  73% (55/75)\u001b[K\rremote: Counting objects:  74% (56/75)\u001b[K\rremote: Counting objects:  76% (57/75)\u001b[K\rremote: Counting objects:  77% (58/75)\u001b[K\rremote: Counting objects:  78% (59/75)\u001b[K\rremote: Counting objects:  80% (60/75)\u001b[K\rremote: Counting objects:  81% (61/75)\u001b[K\rremote: Counting objects:  82% (62/75)\u001b[K\rremote: Counting objects:  84% (63/75)\u001b[K\rremote: Counting objects:  85% (64/75)\u001b[K\rremote: Counting objects:  86% (65/75)\u001b[K\rremote: Counting objects:  88% (66/75)\u001b[K\rremote: Counting objects:  89% (67/75)\u001b[K\rremote: Counting objects:  90% (68/75)\u001b[K\rremote: Counting objects:  92% (69/75)\u001b[K\rremote: Counting objects:  93% (70/75)\u001b[K\rremote: Counting objects:  94% (71/75)\u001b[K\rremote: Counting objects:  96% (72/75)\u001b[K\rremote: Counting objects:  97% (73/75)\u001b[K\rremote: Counting objects:  98% (74/75)\u001b[K\rremote: Counting objects: 100% (75/75)\u001b[K\rremote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 3296 (delta 19), reused 52 (delta 13), pack-reused 3221\u001b[K\n",
            "Receiving objects: 100% (3296/3296), 674.08 MiB | 34.09 MiB/s, done.\n",
            "Resolving deltas: 100% (1037/1037), done.\n",
            "Checking out files: 100% (2014/2014), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QzHW80FnQWI",
        "colab_type": "code",
        "outputId": "0f752dbe-96e3-4a14-f541-c248c9e57a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%shell\n",
        "cd /tmp\n",
        "mkdir tensorflow\\ ultra96\n",
        "# cp -R ./Edge-AI-Platform-Tutorials/docs/MNIST_tf/* ./tensorflow\\ ultra96"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘tensorflow ultra96’: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjgIqRVrMrLG",
        "colab_type": "code",
        "outputId": "a14f2734-c7b2-4df4-a363-d697f44d8ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "%%shell\n",
        "cd /tmp\n",
        "git clone https://github.com/truongkyle/Luan_van_detect_character.git\n",
        "cd ./Luan_van_detect_character/\n",
        "git pull\n",
        "# cp ./chkpts/* /tmp/tensorflow\\ ultra96\n",
        "# # rm -r /tmp/tensorflow\\ ultra96/chkpts/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Luan_van_detect_character'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 31 (delta 7), reused 26 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (31/31), done.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPHBvQNXr0ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################  Use  this to train/use your own tensorflow model ###############################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc_ElQkSOjVQ",
        "colab_type": "code",
        "outputId": "b16d216e-3a1a-4008-d962-1a6f267c89e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "# %tensorflow_version 1.x\n",
        "# import os\n",
        "# import sys\n",
        "# import shutil\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# os.chdir(\"/tmp/tensorflow ultra96\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB2ObehEOr84",
        "colab_type": "code",
        "outputId": "d3e20411-7179-4d82-851d-9890709f8f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# SCRIPT_DIR = os.getcwd()\n",
        "\n",
        "# TRAIN_GRAPH = 'training_graph.pb'\n",
        "# CHKPT_FILE = 'float_model.ckpt'\n",
        "\n",
        "# CHKPT_DIR = os.path.join(SCRIPT_DIR, 'chkpts')\n",
        "# TB_LOG_DIR = os.path.join(SCRIPT_DIR, 'tb_logs')\n",
        "# CHKPT_PATH = os.path.join(CHKPT_DIR, CHKPT_FILE)\n",
        "# MNIST_DIR = os.path.join(SCRIPT_DIR, 'mnist_dir')\n",
        "\n",
        "\n",
        "# # create a directory for the MNIST dataset if it doesn't already exist\n",
        "# if not (os.path.exists(MNIST_DIR)):\n",
        "#     os.makedirs(MNIST_DIR)\n",
        "#     print(\"Directory \" , MNIST_DIR ,  \"created \") \n",
        "\n",
        "\n",
        "# # create a directory for the TensorBoard data if it doesn't already exist\n",
        "# # delete it and recreate if it already exists\n",
        "# if (os.path.exists(TB_LOG_DIR)):\n",
        "#     shutil.rmtree(TB_LOG_DIR)\n",
        "# os.makedirs(TB_LOG_DIR)\n",
        "# print(\"Directory \" , TB_LOG_DIR ,  \"created \") \n",
        "\n",
        "\n",
        "# # create a directory for the checkpoint if it doesn't already exist\n",
        "# # delete it and recreate if it already exists\n",
        "# if (os.path.exists(CHKPT_DIR)):\n",
        "#     shutil.rmtree(CHKPT_DIR)\n",
        "# os.makedirs(CHKPT_DIR)\n",
        "# print(\"Directory \" , CHKPT_DIR ,  \"created \")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory  /tmp/tensorflow ultra96/tb_logs created \n",
            "Directory  /tmp/tensorflow ultra96/chkpts created \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUil-4DdQ-lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Set some parameter\n",
        "# LEARN_RATE = 0.0001\n",
        "# BATCHSIZE = 100\n",
        "# EPOCHS = 3\n",
        "\n",
        "# # MNIST dataset has 60k images. Training set is 60k, test set is 10k.\n",
        "# # Each image is 28x28x8bits\n",
        "# mnist_dataset = tf.keras.datasets.mnist.load_data('mnist_data')\n",
        "# (x_train, y_train), (x_test, y_test) = mnist_dataset\n",
        "\n",
        "# # scale pixel values from 0:255 to 0:1\n",
        "# # Also converts uint8 values to float\n",
        "# x_train = (x_train/255.0)  \n",
        "# x_test = (x_test/255.0)\n",
        "\n",
        "# # reshape train & test images\n",
        "# x_train = np.reshape(x_train, [-1, 28, 28, 1])\n",
        "# x_test = np.reshape(x_test, [-1, 28, 28, 1])\n",
        "\n",
        "# # one-hot encode the labels\n",
        "# y_train = tf.keras.utils.to_categorical(y_train)\n",
        "# y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WU9D90kezV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # take 5000 images from train set to make a dataset for prediction\n",
        "# x_valid = x_train[55000:]\n",
        "# y_valid = y_train[55000:]\n",
        "\n",
        "# # reduce train dataset to 55000 images\n",
        "# y_train = y_train[:55000]\n",
        "# x_train = x_train[:55000]\n",
        "\n",
        "# # calculate total number of batches\n",
        "# total_batches = int(len(x_train)/BATCHSIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDr6_Bhde4Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # define placeholders for the input data & labels\n",
        "# x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name='images_in')\n",
        "# y = tf.placeholder(tf.float32, [None, 10], name='labels_in')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EifTNAYe6aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # define the CNN\n",
        "# def cnn(x):\n",
        "#   net = tf.layers.conv2d(x, 16, [3, 3], activation=tf.nn.relu)\n",
        "#   net = tf.layers.max_pooling2d(net, pool_size=2, strides=2)\n",
        "#   net = tf.layers.conv2d(net, 32, [3, 3], activation=tf.nn.relu)\n",
        "#   net = tf.layers.flatten(net)\n",
        "#   net = tf.layers.dense(net, units=256, activation=tf.nn.relu)\n",
        "#   logits = tf.layers.dense(net, units=10, activation=None)\n",
        "#   return logits\n",
        "\n",
        "# # build the network, input comes from the 'x' placeholder\n",
        "# logits = cnn(x)\n",
        "# prediction = tf.nn.softmax(logits, name='prediction')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94_tbpY_e9Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # softmax cross entropy loss function\n",
        "# loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=y))\n",
        "\n",
        "# # Adaptive Momentum optimizer - minimize the loss\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=LEARN_RATE, name='Adam').minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqCic_dmfCD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Check to see if the prediction matches the label\n",
        "# correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "\n",
        "#  # Calculate accuracy as mean of the correct predictions\n",
        "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS-3c9TdfE-Q",
        "colab_type": "code",
        "outputId": "4d72b5b3-742d-4a15-ca2e-cbede7f81ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# # TensorBoard data collection\n",
        "# tf.summary.scalar('cross_entropy_loss', loss)\n",
        "# tf.summary.scalar('accuracy', accuracy)\n",
        "# tf.summary.image('input_images', x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_images:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szxErPsOfHUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # set up saver object\n",
        "# from tensorflow.core.protobuf import saver_pb2\n",
        "# saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMDrYKnJfK3S",
        "colab_type": "code",
        "outputId": "03c89f36-60c9-43f1-851e-b81db56ff9a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "# with tf.Session() as sess:\n",
        "\n",
        "#     sess.run(tf.initializers.global_variables())\n",
        "    \n",
        "#     # TensorBoard writer\n",
        "#     writer = tf.summary.FileWriter(TB_LOG_DIR, sess.graph)\n",
        "#     tb_summary = tf.summary.merge_all()\n",
        "\n",
        "#     # Training phase with training data\n",
        "#     print ('-------------------------------------------------------------')\n",
        "#     print ('TRAINING PHASE')\n",
        "#     print ('-------------------------------------------------------------')\n",
        "#     for epoch in range(EPOCHS):\n",
        "#         print (\"Epoch\", epoch+1, \"/\", EPOCHS)\n",
        "\n",
        "#         # process all batches\n",
        "#         for i in range(total_batches):\n",
        "            \n",
        "#             # fetch a batch from training dataset\n",
        "#             batch_x, batch_y = x_train[i*BATCHSIZE:i*BATCHSIZE+BATCHSIZE], y_train[i*BATCHSIZE:i*BATCHSIZE+BATCHSIZE]\n",
        "\n",
        "#             # Run graph for optimization, loss, accuracy - i.e. do the training\n",
        "#             _, s = sess.run([optimizer, tb_summary], feed_dict={x: batch_x, y: batch_y})\n",
        "#             writer.add_summary(s, (epoch*total_batches + i))\n",
        "#             # Display accuracy per 100 batches\n",
        "#             if i % 100 == 0:\n",
        "#               acc = sess.run(accuracy, feed_dict={x: x_test, y: y_test})\n",
        "#               print (' Step: {:4d}  Training accuracy: {:1.4f}'.format(i,acc))\n",
        "\n",
        "\n",
        "#     print ('-------------------------------------------------------------')\n",
        "#     print ('FINISHED TRAINING')\n",
        "#     print('Run `tensorboard --logdir=%s --port 6006 --host localhost` to see the results.' % TB_LOG_DIR)\n",
        "#     print ('-------------------------------------------------------------')\n",
        "#     writer.flush()\n",
        "#     writer.close()\n",
        "\n",
        "\n",
        "#     # Evaluation phase with validation dataset\n",
        "#     print ('EVALUATION PHASE:')\n",
        "#     print (\"Final Accuracy with validation set:\", sess.run(accuracy, feed_dict={x: x_valid, y: y_valid}))\n",
        "#     print ('-------------------------------------------------------------')\n",
        "\n",
        "#     # save post-training checkpoint & graph\n",
        "#     print ('SAVING:')\n",
        "#     save_path = saver.save(sess, os.path.join(CHKPT_DIR, CHKPT_FILE))\n",
        "#     print('Saved checkpoint to %s' % os.path.join(CHKPT_DIR,CHKPT_FILE))\n",
        "#     tf.train.write_graph(sess.graph_def, CHKPT_DIR, TRAIN_GRAPH, as_text=False)\n",
        "#     print('Saved binary graphDef to %s' % os.path.join(CHKPT_DIR,TRAIN_GRAPH))\n",
        "#     print ('-------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "TRAINING PHASE\n",
            "-------------------------------------------------------------\n",
            "Epoch 1 / 3\n",
            " Step:    0  Training accuracy: 0.1135\n",
            " Step:  100  Training accuracy: 0.8581\n",
            " Step:  200  Training accuracy: 0.8983\n",
            " Step:  300  Training accuracy: 0.9183\n",
            " Step:  400  Training accuracy: 0.9269\n",
            " Step:  500  Training accuracy: 0.9388\n",
            "Epoch 2 / 3\n",
            " Step:    0  Training accuracy: 0.9416\n",
            " Step:  100  Training accuracy: 0.9455\n",
            " Step:  200  Training accuracy: 0.9498\n",
            " Step:  300  Training accuracy: 0.9543\n",
            " Step:  400  Training accuracy: 0.9562\n",
            " Step:  500  Training accuracy: 0.9628\n",
            "Epoch 3 / 3\n",
            " Step:    0  Training accuracy: 0.9644\n",
            " Step:  100  Training accuracy: 0.9664\n",
            " Step:  200  Training accuracy: 0.9697\n",
            " Step:  300  Training accuracy: 0.9688\n",
            " Step:  400  Training accuracy: 0.9693\n",
            " Step:  500  Training accuracy: 0.9727\n",
            "-------------------------------------------------------------\n",
            "FINISHED TRAINING\n",
            "Run `tensorboard --logdir=/tmp/tensorflow ultra96/tb_logs --port 6006 --host localhost` to see the results.\n",
            "-------------------------------------------------------------\n",
            "EVALUATION PHASE:\n",
            "Final Accuracy with validation set: 0.9778\n",
            "-------------------------------------------------------------\n",
            "SAVING:\n",
            "WARNING:tensorflow:*******************************************************\n",
            "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
            "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
            "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
            "WARNING:tensorflow:now on by default.\n",
            "WARNING:tensorflow:*******************************************************\n",
            "Saved checkpoint to /tmp/tensorflow ultra96/chkpts/float_model.ckpt\n",
            "Saved binary graphDef to /tmp/tensorflow ultra96/chkpts/training_graph.pb\n",
            "-------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRVkRaqbRse7",
        "colab_type": "code",
        "outputId": "08a88b3e-92c8-4c71-b775-fbdc95b3bce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.chdir(\"/tmp/tensorflow ultra96\")\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "!rm -r /tmp/tensorflow\\ ultra96/chkpts/*\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "def load_data (path_data):\n",
        "    rows = []\n",
        "#     with open('Plate_license_train.csv', 'r') as csv_file:\n",
        "    with open(path_data, 'r') as csv_file:\n",
        "        result = csv.reader(csv_file)\n",
        "        # đọc từng dòng của file và thêm vào list rows, mỗi phần tử của list là một dòng\n",
        "        for row in result:\n",
        "            rows.append(row)\n",
        "    data = []\n",
        "    label = []\n",
        "    \n",
        "    for letter in rows :\n",
        "        x = np.array([int(j) for j in letter[1:]])\n",
        "        x = x.reshape(28, 28)\n",
        "        \n",
        "        data.append(x)\n",
        "        label.append(int(letter[0]))\n",
        "            \n",
        "    return data, label\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "path_train = '/tmp/Luan_van_detect_character/Plate_license_train.csv'\n",
        "path_test = '/tmp/Luan_van_detect_character/Plate_license_test.csv'\n",
        "path_val = '/tmp/Luan_van_detect_character/Plate_license_val.csv'\n",
        "\n",
        "\n",
        "data_train = []\n",
        "label_train = []\n",
        "\n",
        "data_test = []\n",
        "label_test = []\n",
        "\n",
        "data_val = []\n",
        "label_val = []\n",
        "\n",
        "data_train, label_train = load_data(path_train)\n",
        "data_test, label_test = load_data(path_test)\n",
        "data_val, label_val = load_data(path_val)\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "get_ipython().run_line_magic('tensorflow_version', '1.x')\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "SCRIPT_DIR = os.getcwd()\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "TRAIN_GRAPH = 'training_graph.pb'\n",
        "CHKPT_FILE = 'float_model.ckpt'\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "CHKPT_DIR = os.path.join(SCRIPT_DIR, 'chkpts')\n",
        "TB_LOG_DIR = os.path.join(SCRIPT_DIR, 'tb_logs')\n",
        "CHKPT_PATH = os.path.join(CHKPT_DIR, CHKPT_FILE)\n",
        "MNIST_DIR = os.path.join(SCRIPT_DIR, 'mnist_dir')\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "if not (os.path.exists(MNIST_DIR)):\n",
        "    os.makedirs(MNIST_DIR)\n",
        "    print(\"Directory \" , MNIST_DIR ,  \"created \") \n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "if (os.path.exists(TB_LOG_DIR)):\n",
        "    shutil.rmtree(TB_LOG_DIR)\n",
        "os.makedirs(TB_LOG_DIR)\n",
        "print(\"Directory \" , TB_LOG_DIR ,  \"created \") \n",
        "\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "if (os.path.exists(CHKPT_DIR)):\n",
        "    shutil.rmtree(CHKPT_DIR)\n",
        "os.makedirs(CHKPT_DIR)\n",
        "print(\"Directory \" , CHKPT_DIR ,  \"created \")\n",
        "\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "LEARN_RATE = 0.0001\n",
        "BATCHSIZE = 50\n",
        "EPOCHS = 3\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "\n",
        "x_train = data_train\n",
        "y_train  = label_train\n",
        "\n",
        "x_test = data_test\n",
        "y_test = label_test\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "print(type(data_train))\n",
        "x_train = np.reshape(x_train, [-1, 28, 28, 1])\n",
        "x_test = np.reshape(x_test, [-1, 28, 28, 1])\n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "\n",
        "x_train = (x_train/255.0)  \n",
        "x_test = (x_test/255.0)\n",
        "\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "\n",
        "# one-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "# In[16]:\n",
        "\n",
        "\n",
        "x_valid = data_val\n",
        "y_valid = label_val\n",
        "\n",
        "x_valid = np.reshape(x_valid, [-1, 28, 28, 1])\n",
        "x_valid = (x_valid/255.0)\n",
        "y_valid  = tf.keras.utils.to_categorical(y_valid)\n",
        "\n",
        "\n",
        "# In[17]:\n",
        "\n",
        "\n",
        "total_batches = int(len(x_train)/BATCHSIZE)\n",
        "\n",
        "\n",
        "# In[18]:\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name='images_in')\n",
        "y = tf.placeholder(tf.float32, [None, 10], name='labels_in')\n",
        "\n",
        "\n",
        "# In[19]:\n",
        "\n",
        "\n",
        "def cnn(x):\n",
        "  '''\n",
        "  Build the convolution neural network\n",
        "  arguments:\n",
        "    inputs: the input tensor - shape must be [None,28,28,1]\n",
        "  '''\n",
        "  net = tf.layers.conv2d(x, 16, [3, 3], activation=tf.nn.relu)\n",
        "  net = tf.layers.max_pooling2d(net, pool_size=2, strides=2)\n",
        "  net = tf.layers.conv2d(net, 32, [3, 3], activation=tf.nn.relu)\n",
        "  net = tf.layers.flatten(net)\n",
        "  net = tf.layers.dense(net, units=256, activation=tf.nn.relu)\n",
        "  logits = tf.layers.dense(net, units=10, activation=None)\n",
        "  return logits\n",
        "\n",
        "\n",
        "# In[20]:\n",
        "\n",
        "\n",
        "# build the network, input comes from the 'x' placeholder\n",
        "logits = cnn(x)\n",
        "\n",
        "\n",
        "# In[21]:\n",
        "\n",
        "\n",
        "loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=y))\n",
        "\n",
        "\n",
        "# In[22]:\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=LEARN_RATE, name='Adam').minimize(loss)\n",
        "\n",
        "\n",
        "# In[23]:\n",
        "\n",
        "\n",
        "# Check to see if the prediction matches the label\n",
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "\n",
        "\n",
        "# In[24]:\n",
        "\n",
        "\n",
        "# Calculate accuracy as mean of the correct predictions\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "\n",
        "# In[25]:\n",
        "\n",
        "\n",
        "# TensorBoard data collection\n",
        "tf.summary.scalar('cross_entropy_loss', loss)\n",
        "tf.summary.scalar('accuracy', accuracy)\n",
        "tf.summary.image('input_images', x)\n",
        "\n",
        "\n",
        "# In[26]:\n",
        "\n",
        "\n",
        "# set up saver object\n",
        "from tensorflow.core.protobuf import saver_pb2\n",
        "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
        "\n",
        "\n",
        "# In[27]:\n",
        "\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    sess.run(tf.initializers.global_variables())\n",
        "    \n",
        "    # TensorBoard writer\n",
        "    writer = tf.summary.FileWriter(TB_LOG_DIR, sess.graph)\n",
        "    tb_summary = tf.summary.merge_all()\n",
        "\n",
        "    # Training phase with training data\n",
        "    print ('-------------------------------------------------------------')\n",
        "    print ('TRAINING PHASE')\n",
        "    print ('-------------------------------------------------------------')\n",
        "    for epoch in range(EPOCHS):\n",
        "        print (\"Epoch\", epoch+1, \"/\", EPOCHS)\n",
        "\n",
        "        # process all batches\n",
        "        for i in range(total_batches):\n",
        "            \n",
        "            # fetch a batch from training dataset\n",
        "            batch_x, batch_y = x_train[i*BATCHSIZE:i*BATCHSIZE+BATCHSIZE], y_train[i*BATCHSIZE:i*BATCHSIZE+BATCHSIZE]\n",
        "\n",
        "            # Run graph for optimization, loss, accuracy - i.e. do the training\n",
        "            _, s = sess.run([optimizer, tb_summary], feed_dict={x: batch_x, y: batch_y})\n",
        "            writer.add_summary(s, (epoch*total_batches + i))\n",
        "            # Display accuracy per 100 batches\n",
        "            if i % 100 == 0:\n",
        "              acc = sess.run(accuracy, feed_dict={x: x_test, y: y_test})\n",
        "              print (' Step: {:4d}  Training accuracy: {:1.4f}'.format(i,acc))\n",
        "\n",
        "\n",
        "    print ('-------------------------------------------------------------')\n",
        "    print ('FINISHED TRAINING')\n",
        "    print('Run `tensorboard --logdir=%s --port 6006 --host localhost` to see the results.' % TB_LOG_DIR)\n",
        "    print ('-------------------------------------------------------------')\n",
        "    writer.flush()\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "    # Evaluation phase with test dataset\n",
        "    print ('EVALUATION PHASE:')\n",
        "    print (\"Final Accuracy with validation set:\", sess.run(accuracy, feed_dict={x: x_valid, y: y_valid}))\n",
        "    print ('-------------------------------------------------------------')\n",
        "\n",
        "    # save post-training checkpoint & graph\n",
        "    print ('SAVING:')\n",
        "    save_path = saver.save(sess, os.path.join(CHKPT_DIR, CHKPT_FILE))\n",
        "    print('Saved checkpoint to %s' % os.path.join(CHKPT_DIR,CHKPT_FILE))\n",
        "    tf.train.write_graph(sess.graph_def, CHKPT_DIR, TRAIN_GRAPH, as_text=False)\n",
        "    print('Saved binary graphDef to %s' % os.path.join(CHKPT_DIR,TRAIN_GRAPH))\n",
        "    print ('-------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/tmp/tensorflow ultra96/chkpts/*': No such file or directory\n",
            "Directory  /tmp/tensorflow ultra96/mnist_dir created \n",
            "Directory  /tmp/tensorflow ultra96/tb_logs created \n",
            "Directory  /tmp/tensorflow ultra96/chkpts created \n",
            "<class 'list'>\n",
            "-------------------------------------------------------------\n",
            "TRAINING PHASE\n",
            "-------------------------------------------------------------\n",
            "Epoch 1 / 3\n",
            " Step:    0  Training accuracy: 0.1078\n",
            " Step:  100  Training accuracy: 0.9671\n",
            "Epoch 2 / 3\n",
            " Step:    0  Training accuracy: 0.9755\n",
            " Step:  100  Training accuracy: 0.9765\n",
            "Epoch 3 / 3\n",
            " Step:    0  Training accuracy: 0.9807\n",
            " Step:  100  Training accuracy: 0.9804\n",
            "-------------------------------------------------------------\n",
            "FINISHED TRAINING\n",
            "Run `tensorboard --logdir=/tmp/tensorflow ultra96/tb_logs --port 6006 --host localhost` to see the results.\n",
            "-------------------------------------------------------------\n",
            "EVALUATION PHASE:\n",
            "Final Accuracy with validation set: 0.98175436\n",
            "-------------------------------------------------------------\n",
            "SAVING:\n",
            "WARNING:tensorflow:*******************************************************\n",
            "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
            "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
            "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
            "WARNING:tensorflow:now on by default.\n",
            "WARNING:tensorflow:*******************************************************\n",
            "Saved checkpoint to /tmp/tensorflow ultra96/chkpts/float_model.ckpt\n",
            "Saved binary graphDef to /tmp/tensorflow ultra96/chkpts/training_graph.pb\n",
            "-------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSfTAUcl61A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMtWL4vKf43E",
        "colab_type": "code",
        "outputId": "71e5bb0d-8439-47c1-c0fc-78246a975288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "# delete previous results\n",
        "!rm -rf ./freeze\n",
        "!mkdir ./freeze\n",
        "!pwd\n",
        "# !freeze_graph --input_graph=./chkpts/training_graph.pb \\\n",
        "#               --input_checkpoint=./chkpts/float_model.ckpt.data-00000-of-00001 \\\n",
        "!freeze_graph --input_graph=./chkpts/training_graph.pb \\\n",
        "              --input_checkpoint=./chkpts/float_model.ckpt \\\n",
        "              --input_binary=true \\\n",
        "              --output_graph=./freeze/frozen_graph.pb \\\n",
        "              --output_node_names=dense_1/BiasAdd\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/tensorflow ultra96\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:249: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "2019-12-06 05:01:24.614745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-06 05:01:24.615454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 8.85GiB\n",
            "2019-12-06 05:01:24.615496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-12-06 05:01:24.989125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-06 05:01:24.989283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-12-06 05:01:24.989335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-12-06 05:01:24.989486: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-06 05:01:24.989573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8571 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVGPiHDvhHx7",
        "colab_type": "code",
        "outputId": "7de6075a-6e64-4b6b-cb43-a2f2a54ee5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.contrib import image\n",
        "SCRIPT_DIR = os.getcwd()\n",
        "CALIB_DIR = os.path.join(SCRIPT_DIR, 'calib_dir')\n",
        "IMAGE_LIST_FILE = 'calib_list.txt'\n",
        "\n",
        "if (os.path.exists(CALIB_DIR)):\n",
        "    shutil.rmtree(CALIB_DIR)\n",
        "os.makedirs(CALIB_DIR)\n",
        "print('Directory', CALIB_DIR, 'created')\n",
        "\n",
        "# get MNIST datasets as numpy arrays\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_test_255 = (x_train * 255).astype(np.uint8)\n",
        "\n",
        "# create file for list of calibration images\n",
        "f = open(os.path.join(CALIB_DIR, IMAGE_LIST_FILE), 'w')\n",
        "\n",
        "# use openCV to save .png images\n",
        "for i in range(len(x_test_255)):\n",
        "    cv2.imwrite(os.path.join(CALIB_DIR,'x_test_'+str(i)+'.png'), x_test_255[i])\n",
        "    f.write('x_test_'+str(i)+'.png\\n')\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Directory /tmp/tensorflow ultra96/calib_dir created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hsd64YEhRc5",
        "colab_type": "code",
        "outputId": "bd2d6721-9554-4819-eff0-3e43c8333a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "calib_image_dir = \"./calib_dir/\"\n",
        "calib_image_list = \"./calib_dir/calib_list.txt\"\n",
        "calib_batch_size = 50\n",
        "def calib_input(iter):\n",
        "  images = []\n",
        "  line = open(calib_image_list).readlines()\n",
        "  for index in range(0, calib_batch_size):\n",
        "    curline = line[iter * calib_batch_size + index]\n",
        "    calib_image_name = curline.strip()\n",
        "\n",
        "    # read image as grayscale, returns numpy array (28,28)\n",
        "    image = cv2.imread(calib_image_dir + calib_image_name, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # scale the pixel values to range 0 to 1.0\n",
        "    image = image/255.0\n",
        "\n",
        "    # reshape numpy array to be (28,28,1)\n",
        "    image = image.reshape((image.shape[0], image.shape[1], 1))\n",
        "    images.append(image)\n",
        "  return {\"images_in\": images}\n",
        "\n",
        "# delete previous results\n",
        "!rm -rf ./quantize_results\n",
        "\n",
        "!decent_q quantize \\\n",
        "  --input_frozen_graph ./freeze/frozen_graph.pb \\\n",
        "  --input_nodes images_in \\\n",
        "  --input_shapes ?,28,28,1 \\\n",
        "  --output_nodes dense_1/BiasAdd \\\n",
        "  --method 1 \\\n",
        "  --input_fn graph_input_fn.calib_input \\\n",
        "  --gpu 0 \\\n",
        "  --calib_iter 50\n",
        "  #--calib_iter 200 # Set iter * iter_batch_size # 50 < num_calib_image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "INFO: Checking Float Graph...\n",
            "2019-12-06 05:11:36.343793: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO: Float Graph Check Done.\n",
            "INFO: Calibrating for 50 iterations...\n",
            "100% (50 of 50) |#########################| Elapsed Time: 0:00:01 Time:  0:00:01\n",
            "INFO: Calibration Done.\n",
            "INFO: Generating Deploy Model...\n",
            "INFO: Deploy Model Generated.\n",
            "********************* Quantization Summary *********************      \n",
            "INFO: Output:       \n",
            "  quantize_eval_model: ./quantize_results/quantize_eval_model.pb       \n",
            "  deploy_model: ./quantize_results/deploy_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KhtngGz-op9",
        "colab_type": "code",
        "outputId": "448d8400-6046-4195-f2e2-db54ec4508e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "%%shell\n",
        "python eval_graph.py \\\n",
        "  --graph ./freeze/frozen_graph.pb \\\n",
        "  --input_node images_in \\\n",
        "  --output_node dense_1/BiasAdd \\\n",
        "  --gpu 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From eval_graph.py:60: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "2019-12-06 04:24:26.095604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-06 04:24:26.096303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 8.85GiB\n",
            "2019-12-06 04:24:26.096342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-12-06 04:24:26.395410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-06 04:24:26.395473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-12-06 04:24:26.395491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-12-06 04:24:26.395604: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-06 04:24:26.395676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8571 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            " Top 1 accuracy with validation set: 0.3189\n",
            " Top 5 accuracy with validation set: 0.7889\n",
            "FINISHED!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQm45dGlmAku",
        "colab_type": "code",
        "outputId": "382ee2c3-df90-4447-eaf7-19f70063d030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        }
      },
      "source": [
        "%%shell\n",
        "python eval_graph.py \\\n",
        "  --graph ./quantize_results/quantize_eval_model.pb \\\n",
        "  --input_node images_in \\\n",
        "  --output_node dense_1/BiasAdd \\\n",
        "  --gpu 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From eval_graph.py:60: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "Traceback (most recent call last):\n",
            "  File \"eval_graph.py\", line 82, in <module>\n",
            "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"eval_graph.py\", line 61, in main\n",
            "    graph_eval(input_graph_def, FLAGS.input_node, FLAGS.output_node)\n",
            "  File \"eval_graph.py\", line 26, in graph_eval\n",
            "    tf.import_graph_def(input_graph_def,name = '')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 418, in import_graph_def\n",
            "    graph._c_graph, serialized, options)  # pylint: disable=protected-access\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'FixNeuron' in binary running on a1785405fea0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-94b8cf32ce03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python eval_graph.py \\\\\\n  --graph ./quantize_results/quantize_eval_model.pb \\\\\\n  --input_node images_in \\\\\\n  --output_node dense_1/BiasAdd \\\\\\n  --gpu 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 138\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'python eval_graph.py \\\n  --graph ./quantize_results/quantize_eval_model.pb \\\n  --input_node images_in \\\n  --output_node dense_1/BiasAdd \\\n  --gpu 0' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgjDsS5In5h0",
        "colab_type": "code",
        "outputId": "67fd45b2-a366-4816-f66e-41ae2bb9869b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "%%shell\n",
        "# delete previous results\n",
        "rm -rf ./compile\n",
        "mkdir compile\n",
        "\n",
        "dnnc \\\n",
        "   --parser=tensorflow \\\n",
        "   --frozen_pb=./quantize_results/deploy_model.pb \\\n",
        "   --dcf=/tmp/dnndk_3.1_dummy/host_x86/dcf/Ultra96.dcf \\\n",
        "   --cpu_arch=arm64 \\\n",
        "   --output_dir=./compile \\\n",
        "   --save_kernel \\\n",
        "   --mode normal \\\n",
        "   --net_name=mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "DNNC Kernel topology \"mnist_kernel_graph.jpg\" for network \"mnist\"\n",
            "DNNC kernel list info for network \"mnist\"\n",
            "                               Kernel ID : Name\n",
            "                                       0 : mnist\n",
            "\n",
            "                             Kernel Name : mnist\n",
            "--------------------------------------------------------------------------------\n",
            "                             Kernel Type : DPUKernel\n",
            "                               Code Size : 7.44KB\n",
            "                              Param Size : 0.95MB\n",
            "                           Workload MACs : 3.30MOPS\n",
            "                         IO Memory Space : 7.19KB\n",
            "                              Mean Value : 0, 0, 0, \n",
            "                              Node Count : 4\n",
            "                            Tensor Count : 5\n",
            "                    Input Node(s)(H*W*C)\n",
            "                        conv2d_Conv2D(0) : 28*28*1\n",
            "                   Output Node(s)(H*W*C)\n",
            "                       dense_1_MatMul(0) : 1*1*10\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIpb3UWB6Eet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}